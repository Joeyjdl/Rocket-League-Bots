{"Policy Entropy": 0.8424478769302368, "Cumulative Timesteps": 350000, "Policy Update Magnitude": 0.15095160901546478, "Collected Steps per Second": 1166.5809027495784, "Value Function Update Magnitude": 0.23536688089370728, "x_vel": -40.5153772130315, "_runtime": 283.14213848114014, "Overall Steps per Second": 1146.2984749851423, "Timestep Collection Time": 42.86029360000002, "PPO Batch Consumption Time": 0.03724511464436849, "Value Function Loss": 0.9759399692217509, "Total Iteration Time": 43.618657, "Cumulative Model Updates": 15, "z_vel": 18.80920435774043, "_timestamp": 1708707914.0044584, "Timesteps Collected": 50000, "SB3 Clip Fraction": 0.014846666599623859, "Mean KL Divergence": 0.002595218849213173, "Timestep Consumption Time": 0.758363399999979, "_step": 13, "y_vel": 413.46643733786124, "Policy Reward": 0.02030224680393168, "_wandb": {"runtime": 280}}