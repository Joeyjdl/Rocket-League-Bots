Created new wandb run! 90zq7pqm
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,03414
Policy Entropy: 0,84263
Value Function Loss: nan
Mean KL Divergence: -0,00000
SB3 Clip Fraction: 0,00000
Policy Update Magnitude: 0,10430
Value Function Update Magnitude: 0,10347
Collected Steps per Second: 16.612,45956
Overall Steps per Second: 12.079,62907
Timestep Collection Time: 3,01147
Timestep Consumption Time: 1,13004
PPO Batch Consumption Time: 0,39288
Total Iteration Time: 4,14152
Cumulative Model Updates: 1
Cumulative Timesteps: 50.028
Timesteps Collected: 50.028
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,00783
Policy Entropy: 0,82814
Value Function Loss: 0,25894
Mean KL Divergence: 0,00122
SB3 Clip Fraction: 0,00097
Policy Update Magnitude: 0,13612
Value Function Update Magnitude: 0,13296
Collected Steps per Second: 16.670,30717
Overall Steps per Second: 12.691,48040
Timestep Collection Time: 2,99958
Timestep Consumption Time: 0,94038
PPO Batch Consumption Time: 0,12671
Total Iteration Time: 3,93997
Cumulative Model Updates: 3
Cumulative Timesteps: 100.032
Timesteps Collected: 50.004
--------END ITERATION REPORT--------
Saving checkpoint 100032...
Checkpoint 100032 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,01780
Policy Entropy: 0,82338
Value Function Loss: 0,17101
Mean KL Divergence: 0,00286
SB3 Clip Fraction: 0,02027
Policy Update Magnitude: 0,12260
Value Function Update Magnitude: 0,13570
Collected Steps per Second: 21.434,01165
Overall Steps per Second: 16.163,42626
Timestep Collection Time: 2,33367
Timestep Consumption Time: 0,76097
PPO Batch Consumption Time: 0,03470
Total Iteration Time: 3,09464
Cumulative Model Updates: 5
Cumulative Timesteps: 150.052
Timesteps Collected: 50.020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0,03072
Policy Entropy: 0,82182
Value Function Loss: 0,17776
Mean KL Divergence: 0,00179
SB3 Clip Fraction: 0,01019
Policy Update Magnitude: 0,16502
Value Function Update Magnitude: 0,19543
Collected Steps per Second: 17.407,56816
Overall Steps per Second: 13.406,24220
Timestep Collection Time: 2,87231
Timestep Consumption Time: 0,85729
PPO Batch Consumption Time: 0,02171
Total Iteration Time: 3,72961
Cumulative Model Updates: 8
Cumulative Timesteps: 200.052
Timesteps Collected: 50.000
--------END ITERATION REPORT--------
Saving checkpoint 200052...
Checkpoint 200052 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,01506
Policy Entropy: 0,81972
Value Function Loss: 0,01529
Mean KL Divergence: 0,00202
SB3 Clip Fraction: 0,00785
Policy Update Magnitude: 0,13389
Value Function Update Magnitude: 0,16441
Collected Steps per Second: 20.114,79399
Overall Steps per Second: 14.813,47534
Timestep Collection Time: 2,48593
Timestep Consumption Time: 0,88964
PPO Batch Consumption Time: 0,06967
Total Iteration Time: 3,37558
Cumulative Model Updates: 11
Cumulative Timesteps: 250.056
Timesteps Collected: 50.004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0,00678
Policy Entropy: 0,81191
Value Function Loss: 0,01163
Mean KL Divergence: 0,00257
SB3 Clip Fraction: 0,02065
Policy Update Magnitude: 0,10843
Value Function Update Magnitude: 0,13110
Collected Steps per Second: 22.430,29975
Overall Steps per Second: 16.230,90161
Timestep Collection Time: 2,23038
Timestep Consumption Time: 0,85189
PPO Batch Consumption Time: 0,02926
Total Iteration Time: 3,08227
Cumulative Model Updates: 14
Cumulative Timesteps: 300.084
Timesteps Collected: 50.028
--------END ITERATION REPORT--------
Saving checkpoint 300084...
Checkpoint 300084 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0,02690
Policy Entropy: 0,80098
Value Function Loss: 0,01219
Mean KL Divergence: 0,00183
SB3 Clip Fraction: 0,00665
Policy Update Magnitude: 0,09474
Value Function Update Magnitude: 0,11884
Collected Steps per Second: 21.670,82343
Overall Steps per Second: 15.160,46283
Timestep Collection Time: 2,30873
Timestep Consumption Time: 0,99144
PPO Batch Consumption Time: 0,08604
Total Iteration Time: 3,30016
Cumulative Model Updates: 17
Cumulative Timesteps: 350.116
Timesteps Collected: 50.032
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0,01249
Policy Entropy: 0,78992
Value Function Loss: 0,00960
Mean KL Divergence: 0,00222
SB3 Clip Fraction: 0,01269
Policy Update Magnitude: 0,08491
Value Function Update Magnitude: 0,11783
Collected Steps per Second: 23.755,51570
Overall Steps per Second: 17.428,77205
Timestep Collection Time: 2,10520
Timestep Consumption Time: 0,76420
PPO Batch Consumption Time: 0,02746
Total Iteration Time: 2,86939
Cumulative Model Updates: 20
Cumulative Timesteps: 400.126
Timesteps Collected: 50.010
--------END ITERATION REPORT--------
Saving checkpoint 400126...
Checkpoint 400126 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,03922
Policy Entropy: 0,78088
Value Function Loss: 0,01776
Mean KL Divergence: 0,00218
SB3 Clip Fraction: 0,01203
Policy Update Magnitude: 0,08091
Value Function Update Magnitude: 0,12622
Collected Steps per Second: 22.471,75664
Overall Steps per Second: 15.212,01483
Timestep Collection Time: 2,22564
Timestep Consumption Time: 1,06216
PPO Batch Consumption Time: 0,10654
Total Iteration Time: 3,28780
Cumulative Model Updates: 23
Cumulative Timesteps: 450.140
Timesteps Collected: 50.014
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,01572
Policy Entropy: 0,77458
Value Function Loss: 0,01761
Mean KL Divergence: 0,00190
SB3 Clip Fraction: 0,00817
Policy Update Magnitude: 0,08362
Value Function Update Magnitude: 0,13690
Collected Steps per Second: 22.840,94142
Overall Steps per Second: 16.775,68413
Timestep Collection Time: 2,18958
Timestep Consumption Time: 0,79164
PPO Batch Consumption Time: 0,02908
Total Iteration Time: 2,98122
Cumulative Model Updates: 26
Cumulative Timesteps: 500.152
Timesteps Collected: 50.012
--------END ITERATION REPORT--------
Saving checkpoint 500152...
Checkpoint 500152 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,01483
Policy Entropy: 0,76978
Value Function Loss: 0,01659
Mean KL Divergence: 0,00247
SB3 Clip Fraction: 0,01509
Policy Update Magnitude: 0,08909
Value Function Update Magnitude: 0,13799
Collected Steps per Second: 22.897,56809
Overall Steps per Second: 16.626,88504
Timestep Collection Time: 2,18381
Timestep Consumption Time: 0,82361
PPO Batch Consumption Time: 0,02299
Total Iteration Time: 3,00742
Cumulative Model Updates: 29
Cumulative Timesteps: 550.156
Timesteps Collected: 50.004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0,00867
Policy Entropy: 0,76817
Value Function Loss: 0,01465
Mean KL Divergence: 0,00241
SB3 Clip Fraction: 0,01565
Policy Update Magnitude: 0,08396
Value Function Update Magnitude: 0,13399
Collected Steps per Second: 20.704,73840
Overall Steps per Second: 14.769,08150
Timestep Collection Time: 2,41607
Timestep Consumption Time: 0,97101
PPO Batch Consumption Time: 0,08417
Total Iteration Time: 3,38708
Cumulative Model Updates: 32
Cumulative Timesteps: 600.180
Timesteps Collected: 50.024
--------END ITERATION REPORT--------
Saving checkpoint 600180...
Checkpoint 600180 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,05313
Policy Entropy: 0,77098
Value Function Loss: 0,01812
Mean KL Divergence: 0,00213
SB3 Clip Fraction: 0,01096
Policy Update Magnitude: 0,08814
Value Function Update Magnitude: 0,13857
Collected Steps per Second: 20.323,29244
Overall Steps per Second: 15.576,57485
Timestep Collection Time: 2,46033
Timestep Consumption Time: 0,74975
PPO Batch Consumption Time: 0,01888
Total Iteration Time: 3,21008
Cumulative Model Updates: 35
Cumulative Timesteps: 650.182
Timesteps Collected: 50.002
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,00822
Policy Entropy: 0,77688
Value Function Loss: 0,01812
Mean KL Divergence: 0,00285
SB3 Clip Fraction: 0,02124
Policy Update Magnitude: 0,08976
Value Function Update Magnitude: 0,14729
Collected Steps per Second: 19.461,34933
Overall Steps per Second: 14.116,72899
Timestep Collection Time: 2,56961
Timestep Consumption Time: 0,97286
PPO Batch Consumption Time: 0,02923
Total Iteration Time: 3,54246
Cumulative Model Updates: 38
Cumulative Timesteps: 700.190
Timesteps Collected: 50.008
--------END ITERATION REPORT--------
Saving checkpoint 700190...
Checkpoint 700190 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,00353
Policy Entropy: 0,78459
Value Function Loss: 0,01612
Mean KL Divergence: 0,00211
SB3 Clip Fraction: 0,01194
Policy Update Magnitude: 0,09099
Value Function Update Magnitude: 0,15170
Collected Steps per Second: 17.763,88295
Overall Steps per Second: 13.280,15076
Timestep Collection Time: 2,81493
Timestep Consumption Time: 0,95039
PPO Batch Consumption Time: 0,03507
Total Iteration Time: 3,76532
Cumulative Model Updates: 41
Cumulative Timesteps: 750.194
Timesteps Collected: 50.004
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0,03168
Policy Entropy: 0,79397
Value Function Loss: 0,01612
Mean KL Divergence: 0,00170
SB3 Clip Fraction: 0,00739
Policy Update Magnitude: 0,09450
Value Function Update Magnitude: 0,11331
Collected Steps per Second: 20.465,16760
Overall Steps per Second: 15.677,85335
Timestep Collection Time: 2,44357
Timestep Consumption Time: 0,74616
PPO Batch Consumption Time: 0,01839
Total Iteration Time: 3,18972
Cumulative Model Updates: 44
Cumulative Timesteps: 800.202
Timesteps Collected: 50.008
--------END ITERATION REPORT--------
Saving checkpoint 800202...
Checkpoint 800202 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,02017
Policy Entropy: 0,80439
Value Function Loss: 0,01699
Mean KL Divergence: 0,00209
SB3 Clip Fraction: 0,00907
Policy Update Magnitude: 0,09741
Value Function Update Magnitude: 0,09040
Collected Steps per Second: 21.662,97654
Overall Steps per Second: 16.142,77277
Timestep Collection Time: 2,30845
Timestep Consumption Time: 0,78940
PPO Batch Consumption Time: 0,01837
Total Iteration Time: 3,09786
Cumulative Model Updates: 47
Cumulative Timesteps: 850.210
Timesteps Collected: 50.008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0,00820
Policy Entropy: 0,80968
Value Function Loss: 0,02053
Mean KL Divergence: 0,00256
SB3 Clip Fraction: 0,01409
Policy Update Magnitude: 0,10158
Value Function Update Magnitude: 0,09160
Collected Steps per Second: 22.766,66576
Overall Steps per Second: 15.196,56148
Timestep Collection Time: 2,19628
Timestep Consumption Time: 1,09407
PPO Batch Consumption Time: 0,11991
Total Iteration Time: 3,29035
Cumulative Model Updates: 50
Cumulative Timesteps: 900.212
Timesteps Collected: 50.002
--------END ITERATION REPORT--------
Saving checkpoint 900212...
Checkpoint 900212 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: -0,02454
Policy Entropy: 0,82168
Value Function Loss: 0,02091
Mean KL Divergence: 0,00367
SB3 Clip Fraction: 0,03019
Policy Update Magnitude: 0,10586
Value Function Update Magnitude: 0,09933
Collected Steps per Second: 17.370,18679
Overall Steps per Second: 12.540,11851
Timestep Collection Time: 2,87896
Timestep Consumption Time: 1,10889
PPO Batch Consumption Time: 0,11434
Total Iteration Time: 3,98784
Cumulative Model Updates: 53
Cumulative Timesteps: 950.220
Timesteps Collected: 50.008
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,01949
Policy Entropy: 0,84289
Value Function Loss: 0,03016
Mean KL Divergence: 0,00474
SB3 Clip Fraction: 0,04616
Policy Update Magnitude: 0,11040
Value Function Update Magnitude: 0,10318
Collected Steps per Second: 18.330,76573
Overall Steps per Second: 14.081,05202
Timestep Collection Time: 2,72875
Timestep Consumption Time: 0,82355
PPO Batch Consumption Time: 0,03003
Total Iteration Time: 3,55229
Cumulative Model Updates: 56
Cumulative Timesteps: 1.000.240
Timesteps Collected: 50.020
--------END ITERATION REPORT--------
Saving checkpoint 1000240...
Checkpoint 1000240 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,03532
Policy Entropy: 0,85082
Value Function Loss: 0,03465
Mean KL Divergence: 0,00345
SB3 Clip Fraction: 0,02483
Policy Update Magnitude: 0,11937
Value Function Update Magnitude: 0,10970
Collected Steps per Second: 19.231,60698
Overall Steps per Second: 13.847,43344
Timestep Collection Time: 2,60082
Timestep Consumption Time: 1,01125
PPO Batch Consumption Time: 0,09042
Total Iteration Time: 3,61208
Cumulative Model Updates: 59
Cumulative Timesteps: 1.050.258
Timesteps Collected: 50.018
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,02505
Policy Entropy: 0,84689
Value Function Loss: 0,03807
Mean KL Divergence: 0,00262
SB3 Clip Fraction: 0,01413
Policy Update Magnitude: 0,13222
Value Function Update Magnitude: 0,11087
Collected Steps per Second: 18.568,79811
Overall Steps per Second: 14.204,83397
Timestep Collection Time: 2,69290
Timestep Consumption Time: 0,82731
PPO Batch Consumption Time: 0,03207
Total Iteration Time: 3,52021
Cumulative Model Updates: 62
Cumulative Timesteps: 1.100.262
Timesteps Collected: 50.004
--------END ITERATION REPORT--------
Saving checkpoint 1100262...
Checkpoint 1100262 saved!
--------BEGIN ITERATION REPORT--------
Policy Reward: 0,01442
Policy Entropy: 0,86250
Value Function Loss: 0,03737
Mean KL Divergence: 0,00434
SB3 Clip Fraction: 0,04020
Policy Update Magnitude: 0,13318
Value Function Update Magnitude: 0,11089
Collected Steps per Second: 18.842,66626
Overall Steps per Second: 13.628,96582
Timestep Collection Time: 2,65461
Timestep Consumption Time: 1,01551
PPO Batch Consumption Time: 0,08193
Total Iteration Time: 3,67012
Cumulative Model Updates: 65
Cumulative Timesteps: 1.150.282
Timesteps Collected: 50.020
--------END ITERATION REPORT--------
--------BEGIN ITERATION REPORT--------
Policy Reward: -0,09259
Policy Entropy: 0,88212
Value Function Loss: 0,03907
Mean KL Divergence: 0,00445
SB3 Clip Fraction: 0,03948
Policy Update Magnitude: 0,13329
Value Function Update Magnitude: 0,10809
Collected Steps per Second: 17.299,80522
Overall Steps per Second: 13.876,53557
Timestep Collection Time: 2,89090
Timestep Consumption Time: 0,71317
PPO Batch Consumption Time: 0,02908
Total Iteration Time: 3,60407
Cumulative Model Updates: 68
Cumulative Timesteps: 1.200.294
Timesteps Collected: 50.012
--------END ITERATION REPORT--------
Saving checkpoint 1200294...
Checkpoint 1200294 saved!