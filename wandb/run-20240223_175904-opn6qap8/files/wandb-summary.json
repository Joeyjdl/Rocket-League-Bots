{"x_vel": -85.9457232966084, "y_vel": 376.6478050039222, "z_vel": 18.58035276814081, "Cumulative Timesteps": 200000, "_timestamp": 1708707693.440004, "_runtime": 148.99900913238525, "_step": 7, "PPO Batch Consumption Time": 0.11626132329305013, "Cumulative Model Updates": 9, "Policy Entropy": 0.8273348609606425, "Mean KL Divergence": 0.0025998796336352825, "Value Function Loss": 1.5184401273727417, "SB3 Clip Fraction": 0.017093332794805367, "Policy Update Magnitude": 0.16154000163078308, "Value Function Update Magnitude": 0.23472459614276886, "Total Iteration Time": 42.22749689999999, "Timesteps Collected": 50000, "Timestep Collection Time": 41.1290949, "Timestep Consumption Time": 1.098401999999993, "Collected Steps per Second": 1215.684422950917, "Overall Steps per Second": 1184.0626054252343, "Policy Reward": -0.03135377400460725, "_wandb": {"runtime": 148}}