{"x_vel": -36.83471830856763, "y_vel": 351.5201925096703, "z_vel": 16.179609221546425, "Cumulative Timesteps": 150000, "_timestamp": 1708707044.982795, "_runtime": 123.09285688400269, "_step": 5, "PPO Batch Consumption Time": 0.1175994873046875, "Cumulative Model Updates": 6, "Policy Entropy": 0.8319199482599894, "Mean KL Divergence": 0.0033961375011131167, "Value Function Loss": 0.7842173178990682, "SB3 Clip Fraction": 0.029399999417364597, "Policy Update Magnitude": 0.17365364730358124, "Value Function Update Magnitude": 0.22619794309139252, "Total Iteration Time": 39.956357100000005, "Timesteps Collected": 50000, "Timestep Collection Time": 38.847351700000004, "Timestep Consumption Time": 1.109005400000001, "Collected Steps per Second": 1287.089024398026, "Overall Steps per Second": 1251.3653302993428, "Policy Reward": 0.0625397443739007, "_wandb": {"runtime": 122}}